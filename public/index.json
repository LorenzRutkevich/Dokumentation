
[{"content":" Überblick # In diesem Beitrag stellen wir die Ergebnisse einer umfassenden Ablationsstudie vor, mit der wir die Effektivität der einzelnen Komponenten innerhalb der SHIFT-Architektur untersucht haben. Ziel war es, den Einfluss von Attention-Mechanismen, spezialisierten CNN-Modulen (wie Depthwise-Separable-Convolutions und MB-Conv) sowie vortrainierten Gewichten auf die Metriken Dice-Score und F1-Score sowie auf die Modellkomplexität zu evaluieren.\nDabei wurden sechs Varianten des Netzwerks entwickelt und systematisch modifiziert, um zu analysieren, welche Konfigurationen die beste Performance liefern – insbesondere im Kontext der interaktiven Segmentierung.\nAblationsstudie im Detail # Die Ergebnisse der getesteten Modelle fassen wir in folgender Tabelle zusammen:\nDice-Score F1 Parameter F/b (MB) Encoder Bridge Decoder 88,0 81,0 28.817.665 497,88 2x SepConv ✔, Residual ✔, Attention ✔ Pretrained ✔ 2x SepConv ✔, Residual ✔, Attention ✔ 87,8 80,4 31.836.865 984,88 2x SepConv ✔, Residual ✔, Attention ✔ Pretrained ✔ 2x SepConv ✔, Residual ✔, Attention ✔ 87,6 80,2 37.751.681 331,25 1x SepConv ✔, Residual ✘, Attention ✘ Pretrained ✔ 1x SepConv ✘, Residual ✘, Attention ✘ 87,6 80,0 35.012.957 1037,12 1x SepConv ✔, Residual ✔, Attention ✔ Pretrained ✔ 1x SepConv ✔, Residual ✔, Attention ✔, MBConv ✔ 87,3 79,6 46.663.261 801,75 2x SepConv ✘, Residual ✔, Attention ✔ Pretrained ✔ 2x SepConv ✘, Residual ✔, Attention ✔, MBConv ✔ 86,9 78,9 12.845.537 380,38 1x SepConv ✔, Residual ✘, Attention ✘ Pretrained ✘ 1x SepConv ✘, Residual ✘, Attention ✘ Die Tabelle zeigt, dass die Integration von Attention-Mechanismen – insbesondere im Encoder und Decoder – zu den höchsten Dice- und F1-Scores führt. Im Folgenden gehen wir näher auf die wichtigsten untersuchten Komponenten ein.\nAttention-Mechanismen # Zwei unterschiedliche Attention-Mechanismen wurden evaluiert: Efficient-Attention und Quick-Attention. Während Efficient-Attention globale Zusammenhänge im Bild berücksichtigt und so präzisere Ergebnisse liefert, besticht Quick-Attention durch einen deutlich geringeren Rechenaufwand.\nBeim Quick-Attention-Mechanismus wird zunächst auf die Eingabe-Feature-Map eine spezielle Faltung angewendet, die dafür sorgt, dass wichtige Merkmale hervorgehoben werden. Anschließend wird das Ergebnis einer Aktivierung unterzogen, die die Werte normalisiert. Schließlich wird dieses aktivierte Ergebnis zur ursprünglichen Feature-Map hinzugefügt. Vereinfacht gesagt, wird die Feature-Map in zwei Teile geteilt: Einer wird verarbeitet, und das Ergebnis wird dann mit dem unberührten Teil kombiniert, um die finale Attention-Karte zu erhalten.\nDiese Vorgehensweise ist ressourcenschonender als alternative Methoden, wobei der Fokus bei Efficient-Attention auf der Erfassung globaler Abhängigkeiten liegt, was zu einer noch höheren Präzision führt.\nCNN-Module # Ein weiterer Schwerpunkt der Studie lag auf dem Einsatz spezialisierter CNN-Module:\nDepthwise-Separable-Convolutions (DSConv):\nDiese Module ermöglichen es, den Rechenaufwand erheblich zu reduzieren, ohne dabei signifikante Einbußen bei der Genauigkeit zu riskieren. Zum Vergleich wurden auch herkömmliche Convolutionen getestet, die zwar präzise Ergebnisse lieferten, jedoch weniger effizient arbeiteten.\nMB-Conv Module:\nDieses Modul kombiniert mehrere Faltungsschritte, um die Anzahl der Parameter zu senken und gleichzeitig die Tiefe des Modells zu erhöhen. Trotz des zusätzlichen Rechenaufwands führte der Einsatz von MB-Conv nicht zu einer deutlichen Verbesserung der Ergebnisse, sondern erhöhte hauptsächlich die Modellkomplexität.\nVortrainierte Gewichte # Ein wesentlicher Faktor für die Leistungssteigerung war der Einsatz vortrainierter ResNet-Schichten in der sogenannten Bridge-Komponente der Architektur. Diese vortrainierten Gewichte sorgen für eine robuste Initialisierung und verbessern die Fähigkeit des Netzwerks, relevante Merkmale aus den Eingabedaten zu extrahieren – ein besonderer Vorteil, wenn nur begrenzte Trainingsdaten zur Verfügung stehen. Allerdings führt diese Vorgehensweise zu einem Anstieg der Modellparameter und des Speicherbedarfs.\nFazit # Die Ablationsstudie zeigt deutlich, dass die gezielte Integration von Attention-Mechanismen innerhalb der SHIFT-Architektur zu einer signifikanten Leistungssteigerung führt – insbesondere im Hinblick auf die Metriken Dice-Score und F1-Score. Obwohl zusätzliche Module wie MB-Conv die Tiefe des Modells erweitern, sollten sie aufgrund des erhöhten Ressourcenverbrauchs mit Bedacht eingesetzt werden. Ebenso verbessert der Einsatz vortrainierter Gewichte die Merkmalextraktion, erfordert jedoch auch mehr Speicher.\nDiese Erkenntnisse bieten wertvolle Hinweise für die Optimierung zukünftiger Architekturen im Bereich der interaktiven Segmentierung und zeigen, wie durch systematische Variationen einzelner Komponenten die Modellleistung weiter verbessert werden kann.\n","date":"10 February 2025","externalUrl":null,"permalink":"/posts/ablation/","section":"Posts","summary":"Eine detaillierte Analyse, wie verschiedene Konfigurationskomponenten der SHIFT-Architektur die Segmentierungsleistung beeinflussen.","title":"Ablationsstudie der SHIFT-Architektur","type":"posts"},{"content":"","date":"10 February 2025","externalUrl":null,"permalink":"/","section":"SHIFT","summary":"","title":"SHIFT","type":"page"},{"content":" Architektur # Die Architektur des ESRUT-Net basiert auf einem Encoder-Decoder-Modell mit einem U-Net-ähnlichen Verlauf. Neben klassischen CNN-Blöcken sind Transformer-Blöcke sowie vortrainierte Layer integriert.\nEncoder # Zu Beginn wird eine einfache 2D-Convolution auf die Eingabe angewandt, um sie in das geeignete Format zu bringen. Anschließend werden abwechselnd Depthwise-Separable-Convolutions und optional Attention-Mechanismen eingesetzt, um die Features zu extrahieren und den Featurespace schrittweise zu erweitern. Die Ausgabe eines Blocks dient jeweils als Eingabe für den darunterliegenden Block. Diese Layer-Anordnung führt zu einem leistungsfähigen Segmentationsmodell, das dennoch schnell ist und eine geringe Anzahl an Parametern benötigt.\nBridge # Der Brückenabschnitt enthält zusätzliche Layer, die in herkömmlichen Architekturen meist nicht vorkommen. Hier sind ein Transformer-Layer und ein darauf folgender vortrainierter Layer integriert. Diese Struktur ermöglicht eine tiefere Extraktion relevanter Merkmale und erhöht die Stabilität des Modells.\nDecoder # Der Decoder setzt sich aus doppelten Convolutions und optionaler Attention zusammen. Er verarbeitet die Features aus den Decoder-Blöcken und der Bridge und generiert daraus die gewünschte Ausgabe. Auf jeder Stufe wird die Ausgabe in Höhe und Breite jeweils verdoppelt. Abschließend wird ein letzter Convolutional Layer angewandt, um die Endausgabe zu erzeugen.\nVariationen # Durch die flexible Struktur des Modells lassen sich vielfältige Anpassungen und Kombinationen der Schichten realisieren, sodass das Modell auf unterschiedliche Anforderungen hin optimiert werden kann.\n","date":"6 November 2024","externalUrl":null,"permalink":"/posts/network/","section":"Posts","summary":"Das ESRUT-Net, ein Hybridmodel, das CNNs und Transformer in medizinisches ein Segmentationsmodell verschmilzt.","title":"Das Modell im Überblick","type":"posts"},{"content":" Ähnlichkeiten # Das Netzwerk orientiert sich an der U-Net-Architektur von Ronneberger et al., die sich als herausragend für die Segmentierung medizinischer Aufnahmen etabliert hat. Die typische U-Form dieser Architektur wird übernommen, jedoch durch die Integration verschiedenster Layer, Aktivierungen und Transformer-Komponenten weiterentwickelt und optimiert.\nVergleich # Das Eff-ResSepUTransNet erzielt hervorragende Ergebnisse in der semantischen Segmentierung. Es ist bereits das leistungsstärkste Netzwerk, das auf dem speziell für dieses Projekt zusammengestellten Datensatz trainiert wurde, und zählt zudem zu den schnellsten und effizientesten Modellen im Hinblick auf die Parameteranzahl. Auch außerhalb der interaktiven Segmentierung hat sich das Modell bewährt: Es wurde auf Masken des interaktiven Datensatzes semantisch trainiert und lieferte dabei ebenfalls ausgezeichnete Ergebnisse, die gängige Literaturwerte übertreffen würden.\nIn dem unten stehenden Graphen sind ausgewählte Modelle dargestellt, die den aktuellen Stand der Technik sowie ihre Basisarchitekturen repräsentieren. Die Modelle von SHIFT schneiden sowohl hinsichtlich der Parameteranzahl als auch der Metriken unter gleichen Bedingungen am besten ab. Weitere Tests deuten darauf hin, dass das Eff-ResSepUTransNet das Potenzial hat, in weiteren Benchmarks eine Spitzenposition einzunehmen.\n","date":"6 November 2024","externalUrl":null,"permalink":"/posts/netzwerkvergleich/","section":"Posts","summary":"Das Eff-ResSepUTransNet zeigt sich im Vergleich zur Literatur als besonders präzise und gleichzeitig schnell.","title":"Das Modell im Vergleich","type":"posts"},{"content":" Die Methode hinter der interaktiven Segmentation # Die Basis hinter dem Ansatz stellt Koohbanani et al. dar. Hierfür werden sogenannte Inclusion Maps und Exclusion Maps als Leitlinien genutzt, um präzise und effiziente Segmentierungen zu erzeugen – und das mit minimalem Benutzereingriff.\nInclusion Map # Die Inclusion Map wird erstellt, indem ein Benutzer innerhalb eines Zellkerns klickt. Dieser Klick erzeugt eine Karte, bei der der geklickte Punkt auf \u0026ldquo;1\u0026rdquo; gesetzt wird, während alle anderen Pixel den Wert \u0026ldquo;0\u0026rdquo; erhalten. Diese Karte hilft dem Modell, den genauen Bereich des Zellkerns zu erkennen, auf den sich der Benutzer konzentrieren möchte. Ist beispielsweise nur ein Kern von Interesse, genügt die Inclusion Map als präziser Hinweis.\nExclusion Map # In Szenarien, in denen mehrere Zellkerne dicht beieinander liegen, wird zusätzlich eine Exclusion Map erstellt. Diese Karte markiert alle anderen Zellkerne im Bildausschnitt – auch hier werden die entsprechenden Pixel auf \u0026ldquo;1\u0026rdquo; gesetzt, während alle übrigen Pixel den Wert \u0026ldquo;0\u0026rdquo; behalten. So kann das Modell zwischen dicht gepackten Kernen unterscheiden und sicherstellen, dass sich die Segmentierung ausschließlich auf den gewünschten Zellkern konzentriert.\nWährend des Trainings # Im Trainingsprozess werden die Inclusion- und Exclusion Maps variabel eingesetzt. Für die Inclusion Map wird der Klickpunkt zufällig innerhalb des Kerns gewählt – dabei wird ein Mindestabstand zu den Randpixeln eingehalten, um die Robustheit des Modells zu erhöhen. Die Exclusion Map wird auf Basis der Zentren der übrigen Kerne erstellt. Diese Vorgehensweise lehrt das Modell, auch dann eine präzise Segmentierung vorzunehmen, wenn die Eingaben nicht exakt im Kernzentrum liegen.\nErgebnisse der gelenkten (interaktiven) Segmentierung # Die im Rahmen dieses Projekts entwickelten Architekturen übertreffen derzeit alle vergleichbaren Modelle in der interaktiven Segmentierung. Der zugrunde liegende Datensatz wurde speziell für dieses Projekt kuratiert und umfasst 56.130 Trainingsbilder mit zugehörigen Masken sowie 9.905 Testbilder. Die Modelle wurden auf Patches der Größe 128×128 trainiert, was dem Standardansatz dieser Methode entspricht.\nIm Folgenden ein Vergleich einiger Modelle aus der Literatur sowie der eigens entwickelten Ansätze:\nModel Dice Jaccard F1 Parameters Nuclick 84,11 85,42 74,57 66.800.321 UNet 84,61 85,61 74,85 12.583.425 NucDep 85,39 86,65 76,46 69.944.961 UDTransNet 86,46 87,88 78,41 33.799.617 SHIFT-S 86,9 88,2 78,92 12.845.537 SHIFT 88,0 89,56 81,0 28.817.665 Die Ergebnisse zeigen, dass der Einsatz von Attention-Mechanismen, Depthwise-Separable-Convolutions und vortrainierten Schichten in der Architektur – unter dem Namen SHIFT (bisher ESRUT-Net) – zu einer signifikanten Verbesserung der Segmentierungsleistung führt. Im Vergleich zum UDTransNet erzielt SHIFT einen um 1,5 Punkte höheren Dice-Score und einen um 2,6 Punkte besseren F1-Score, bei gleichzeitig effizienterer Parameterverwendung.\nUngelenkte Segmentierung # Neben der interaktiven (gelenkten) Segmentierung zeigt die Architektur ihre universelle Anwendbarkeit auch in ungelenkten Szenarien, bei denen keine zusätzlichen Benutzereingaben vorliegen. Ein besonders anschauliches Beispiel stellt die Segmentierung von Drüsen im Dickdarm dar – eine medizinisch relevante Aufgabe zur Beurteilung des Zustands bei Dickdarmkrebs. Für diese Aufgabe wurde der CRAG-Datensatz genutzt, der ursprünglich zur Evaluierung von Segmentierungsmodellen wie MILD-Net eingeführt wurde.\nSHIFT erzielt in dieser ungelenkten Segmentierung herausragende Ergebnisse:\nDice-Score: 93,4 F1-Score: 92,7 Im Vergleich dazu erreichen andere Modelle folgende Werte:\nModell Dice-Score F1 SHIFT 93,4 92,7 PatchCL 89,2 88,1 Mild-Net 88,3 86,9 G-CNN (C12) 83,4 81,8 Diese Ergebnisse unterstreichen, dass SHIFT – durch die Kombination aus der Erfassung lokaler und globaler Merkmale – nicht nur in der interaktiven, sondern auch in der ungelenkten Segmentierung hervorragende Leistungen erbringt. Die Fähigkeit, präzise und zusammenhängende Regionen zu erfassen, macht SHIFT zu einer optimalen Lösung für verschiedenste medizinische Segmentierungsaufgaben.\nZusammenfassung # Der vorgestellte Ansatz zeigt eindrucksvoll, wie bereits mit minimalen Benutzereingaben durch Inclusion- und Exclusion Maps präzise Segmentierungen erreicht werden können. Gleichzeitig beweist die Architektur unter dem Namen SHIFT, dass sie auch in ungelenkten Anwendungen – wie der Drüsensegmentierung – ihre Überlegenheit demonstriert. Die systematische Integration moderner CNN-Module und Attention-Mechanismen führt zu einer signifikanten Verbesserung der Segmentierungsqualität, was insbesondere in ressourcenarmen Szenarien von großem Vorteil ist.\n","date":"6 November 2024","externalUrl":null,"permalink":"/posts/interactive/","section":"Posts","summary":"Mittels wenigen Klicks zu einer vollen und präzisen Segmentierung von Zellkernen und Zellstrukturen – und darüber hinaus: universelle Ansätze für ungelenkte Segmentierungsaufgaben.","title":"Die Interaktive Segmentation im Überblick","type":"posts"},{"content":" Bestandteile # Der für das Training der interaktiven Methode von SHIFT erstellte Datensatz ist eine Zusammenstellung öffentlich zugänglicher Datensätze aus Veröffentlichungen und Challenges. Alle enthaltenen Datensätze stammen aus ethisch vertretbaren Quellen und zeichnen sich durch hohe Qualität und Diversität aus. Zu den Bestandteilen dieses Datensatzes zählen beispielsweise MoNuSeg und der PanNuke Datensatz, wobei der Großteil des Materials aus menschlichen Proben unterschiedlichster Organe besteht. Überlappende Bilder aus verschiedenen Datensätzen wurden entfernt, um Redundanzen zu vermeiden.\nVorbereitung # Für die automatische Generierung von Trainings-Batches für die interaktive Methode sind vorzugsweise Instanzmasken erforderlich. Diese ermöglichen es, jeden Zellkern als separates Objekt auf einer individuellen Teilmaske darzustellen. Da solche Instanzmasken nicht in allen Datensätzen vorhanden sind, können semantische Masken genutzt werden, bei denen sich die Zellkerne möglicherweise nicht unmittelbar voneinander trennen lassen. Durch Subtraktion vorhandener Randmasken lassen sich die Zellkerne in diesen semantischen Masken voneinander separieren, was die Erstellung von Instanzmasken ermöglicht.\nDie Teilgröße jedes Bildes beträgt 128x128 Pixel. Um den Datensatz weiter zu erweitern, wurden größere Bilder in Teilbilder dieser Größe unterteilt. So entstand ein Datensatz mit insgesamt 56.130 Trainingsbildern und zugehörigen Masken sowie 9.905 Testbildern mit entsprechenden Masken.\n","date":"6 November 2024","externalUrl":null,"permalink":"/posts/datensatz/","section":"Posts","summary":"Für das Training der Modelle von SHIFT wurde ein eigener Datensatz erstellt, der viele Gewebestrukturen präzise abdeckt.","title":"Erstellung des Datensatzes","type":"posts"},{"content":" Funktionsweise des Unsicherheitsmodells # Um den Nutzern eine präzisere und schnellere Analyse zu ermöglichen, habe ich ein neues Verfahren entwickelt, das neben einer herkömmlichen Segmentationsmaske auch eine Unsicherheitsmaske ausgibt. Diese Maske hebt alle Bereiche hervor, in denen sich das Modell bezüglich der Segmentierung unsicher ist. Dafür wurde eine Variante des Eff-ResSepUTransNet mit mehreren Ausgabeköpfen entwickelt. Zusätzlich entstand ein Netzwerk, das als Ausgabeschicht ein weiteres Netzwerk verwendet und somit ein \u0026ldquo;zwei-in-eins-Netzwerk\u0026rdquo; bildet. Dieses Modell generiert sowohl eine herkömmliche Segmentationsmaske als auch eine Unsicherheitsmaske. Für das Training dieser Modelle wurde eine speziell angepasste Loss-Funktion entwickelt, die die präzise Generierung beider Masken sicherstellt.\nErstellung der Maske # Bei der Segmentierung von Zellkernen und anderen Objekten nimmt die Aktivierung des Modells an den Rändern der Objekte oft ab, wodurch Unsicherheiten in diesen Randbereichen auf der Ausgabemaske deutlich sichtbar werden. Daher sind einige Preprocessing-Schritte notwendig, um eine präzisere Vorhersage zu treffen. Der wichtigste Schritt ist die Subtraktion einer Randmaske von der Unsicherheitsmaske. Diese Randmaske kann entweder von einem Modell erzeugt oder aus der semantischen Ausgabe durch einen Algorithmus generiert werden. Dadurch werden alle überlappenden Aktivierungen neutralisiert. Um mögliche kleinere Fehler zu beheben, wird die Maske anschließend erodiert und einer Schwellenwertprüfung unterzogen, um nur die genauen Werte zu erhalten. Auf diese Weise entsteht eine Maske, die die schwierigsten Bereiche zur Segmentierung markiert. Dies kann den Nutzern als Unterstützung dienen oder eine unguided-Segmentierung mit feineren guided-Segmentierungsschritten ermöglichen, was die bestmöglichen Ergebnisse liefert.\n","date":"6 November 2024","externalUrl":null,"permalink":"/posts/uncertainty/","section":"Posts","summary":"Einfachere und bessere Markierung durch das Aufzeigen von Unischerheiten innerhalb des Modells.","title":"Uncertainty-Guidance - Markierung unsicherer Bereiche","type":"posts"},{"content":"","date":"13 June 2022","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]